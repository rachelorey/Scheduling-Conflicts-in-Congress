{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Committee Scheduling Conflicts\n",
    "\n",
    "This scripts analyzes the House Committee Respository to collect the number of scheduling conflicts in each member's schedule.\n",
    "\n",
    "If the same committee has two hearings in the same hour (for example, a committee hearing and a markup), only one of hearing is counted in the analysis of conflicts.\n",
    "\n",
    "##### SEARCH XXX FOR INPUT CHANGES BEFORE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from lxml import html    \n",
    "from datetime import datetime, timedelta\n",
    "import re    \n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "#create directory for specific congress if it doesn't already exist\n",
    "\n",
    "congress = int(input(\"Congress (3-digit number): \"))\n",
    "\n",
    "# Specify directory for this congress\n",
    "directory = str(congress)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "# write something to print results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this pulls hearings for one day\n",
    "def hearingpull(date):\n",
    "\n",
    "    #formatting url\n",
    "    day_url = \"https://docs.house.gov/Committee/Calendar/ByDay.aspx?DayID=\" + date.strftime(\"%m%d%Y\")\n",
    "\n",
    "    #import webpage and create tree\n",
    "    webpage = requests.get(day_url)\n",
    "    tree = html.fromstring(webpage.content)\n",
    "\n",
    "    #importing and formatting hearing titles\n",
    "    hearing_titles = tree.xpath(\"//table//a[@title]//text()[normalize-space()]\")\n",
    "    hearing_titles = [sub.replace('\\r\\n', '') for sub in hearing_titles] \n",
    "    hearing_titles = [sub.strip() for sub in hearing_titles]\n",
    "    hearing_titles = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace(\"???\",\" \") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace(\"'\",\"\") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace('\"',\"\") for sub in hearing_titles]\n",
    "\n",
    "    #import and format committee titles\n",
    "    committee_titles = tree.xpath(\"//table//span[@title]//text()[normalize-space()]\")\n",
    "    committee_titles = [sub.replace('\\r\\n', '') for sub in committee_titles] \n",
    "    committee_titles = [sub.strip() for sub in committee_titles]\n",
    "    committee_titles = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace(\"???\",\" \") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace(\"'\",\"\") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace('\"',\"\") for sub in committee_titles]\n",
    "\n",
    "    #import and format links\n",
    "    link_extension = tree.xpath(\"//table//a//@href\")\n",
    "    link_extension = [\"https://docs.house.gov/Committee/Calendar/\"+ex for ex in link_extension]\n",
    "\n",
    "    #import times and dates\n",
    "    times = list()\n",
    "    dates = list()\n",
    "\n",
    "    for hearing in range(len(link_extension)):\n",
    "        hearing_link = requests.get(link_extension[hearing])\n",
    "        hearing_tree = html.fromstring(hearing_link.content)\n",
    "        try:\n",
    "            datestring = hearing_tree.xpath(\"//div[@class='meeting-date']//p/text()[normalize-space()]\")\n",
    "            #get dates\n",
    "            date = datestring[0][0:datestring[0].find(\"(\")-1]\n",
    "            date = date.replace('\\r\\n', '')\n",
    "            date = date.strip()\n",
    "            #get times\n",
    "            time = datestring[0][datestring[0].find(\"(\"):len(datestring[0])]\n",
    "            time = time.replace('\\r\\n', '')\n",
    "            time = time.replace('(', '')\n",
    "            time = time.replace(')', '')\n",
    "            if time.find(\"-\") > 0:\n",
    "                time = time[0:time.find(\"-\")]\n",
    "            time = time.strip()\n",
    "        except:\n",
    "            date = tree.xpath(\"//div[@id='body']//span[@id='LabelPageTitle']//text()[normalize-space()]\")[0]\n",
    "            times = tree.xpath(\"//div//table[@class='table table-bordered']//tr//td[2]//span[@class='text-small']//text()[normalize-space()]\")\n",
    "            times = [sub.replace('\\r\\n', '') for sub in times] \n",
    "            times = [sub.strip() for sub in times]\n",
    "            times = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in times]\n",
    "            times = [str(sub).replace(\"???\",\" \") for sub in times]\n",
    "            times = [str(sub).replace(\"'\",\"\") for sub in times]\n",
    "            times = [str(sub).replace('\"',\"\") for sub in times]\n",
    "            time = times[hearing]\n",
    "        #append\n",
    "        dates += [date]\n",
    "        times += [time]\n",
    "\n",
    "    #zipping into single dataframe\n",
    "    day_results = pd.DataFrame(zip(dates,committee_titles,hearing_titles,times,link_extension),columns=[\"Date\",\"Committee\",\"Hearing Title\",\"Time\",\"Link\"])\n",
    "\n",
    "    return(day_results)\n",
    "\n",
    "#this pulls hearings for a date range\n",
    "def gethearingrange(datestart,dateend):\n",
    "\n",
    "    results = pd.DataFrame(columns=[\"Date\",\"Committee\",\"Hearing Title\",\"Time\",\"Link\"])\n",
    "\n",
    "    datestart = datetime.strptime(datestart,\"%m/%d/%Y\").date()\n",
    "    dateend = datetime.strptime(dateend,\"%m/%d/%Y\").date()\n",
    "    \n",
    "    #if dateend is in the future, make dateend today\n",
    "    if dateend > datetime.now().date():\n",
    "        dateend = datetime.now().date()\n",
    "\n",
    "    while datestart <= dateend:\n",
    "        # results = results.append(hearingpull(datestart)) #append dep\n",
    "        results = pd.concat([results, hearingpull(datestart)], ignore_index=True)\n",
    "        datestart += timedelta(days=1)\n",
    "    \n",
    "    #remove misc. spaces from committee column\n",
    "    results[\"Committee\"] = [re.sub(' +', ' ',com) for com in results[\"Committee\"]]\n",
    "    \n",
    "    results[\"Time\"] = [time.replace(\"local time\",\"\") for time in results[\"Time\"]]\n",
    "    results[\"Time\"] = [time.strip() for time in results[\"Time\"]]\n",
    "    \n",
    "    results = results.drop_duplicates(subset=[\"Link\"])\n",
    "    \n",
    "    results[\"Hour\"] = [datetime.strptime(time,\"%I:%M %p\").hour for time in results[\"Time\"]]\n",
    "    results.drop_duplicates(subset=[\"Date\",\"Committee\",\"Hour\"],inplace=True)\n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got part way through trying to make this more efficient with concurrent requests, but it's not working yet\n",
    "\n",
    "# import requests\n",
    "\n",
    "# # this pulls hearings for one day\n",
    "# def clean_text(text):\n",
    "#     text = text.replace('\\r\\n', '')\n",
    "#     text = text.strip()\n",
    "#     text = text.encode(\"ascii\", \"replace\").decode(\"utf-8\")\n",
    "#     text = text.replace(\"???\", \" \")\n",
    "#     text = text.replace(\"'\", \"\")\n",
    "#     text = text.replace('\"', \"\")\n",
    "#     return text\n",
    "\n",
    "# import concurrent.futures\n",
    "\n",
    "# def hearingpull(date):\n",
    "#     # Formatting url\n",
    "#     day_url = \"https://docs.house.gov/Committee/Calendar/ByDay.aspx?DayID=\" + date.strftime(\"%m%d%Y\")\n",
    "\n",
    "#     # Create a session for concurrent requests\n",
    "#     session = requests.Session()\n",
    "\n",
    "#     # Send a GET request for the day's webpage\n",
    "#     webpage = session.get(day_url)\n",
    "\n",
    "#     # Import webpage content and create tree\n",
    "#     tree = html.fromstring(webpage.content)\n",
    "\n",
    "#     # Importing and formatting hearing titles\n",
    "#     hearing_titles = tree.xpath(\"//table//a[@title]//text()[normalize-space()]\")\n",
    "#     hearing_titles = [clean_text(title) for title in hearing_titles]\n",
    "\n",
    "#     # Import and format committee titles\n",
    "#     committee_titles = tree.xpath(\"//table//span[@title]//text()[normalize-space()]\")\n",
    "#     committee_titles = [clean_text(title) for title in committee_titles]\n",
    "\n",
    "#     # Import and format links\n",
    "#     link_extension = tree.xpath(\"//table//a//@href\")\n",
    "#     link_extension = [\"https://docs.house.gov/Committee/Calendar/\"+ex for ex in link_extension]\n",
    "\n",
    "#     # Import times and dates\n",
    "#     times = []\n",
    "#     dates = []\n",
    "\n",
    "#     def process_hearing(hearing_link):\n",
    "#         hearing_link = session.get(hearing_link)\n",
    "#         hearing_tree = html.fromstring(hearing_link.content)\n",
    "#         try:\n",
    "#             datestring = hearing_tree.xpath(\"//div[@class='meeting-date']//p/text()[normalize-space()]\")\n",
    "#             # Get dates\n",
    "#             date = datestring[0][0:datestring[0].find(\"(\")-1]\n",
    "#             date = clean_text(date)\n",
    "#             # Get times\n",
    "#             time = datestring[0][datestring[0].find(\"(\"):len(datestring[0])]\n",
    "#             time = clean_text(time)\n",
    "#             if time.find(\"-\") > 0:\n",
    "#                 time = time[0:time.find(\"-\")]\n",
    "#             time = time.strip()\n",
    "#         except:\n",
    "#             date = tree.xpath(\"//div[@id='body']//span[@id='LabelPageTitle']//text()[normalize-space()]\")[0]\n",
    "#             times = tree.xpath(\"//div//table[@class='table table-bordered']//tr//td[2]//span[@class='text-small']//text()[normalize-space()]\")\n",
    "#             times = [clean_text(time) for time in times]\n",
    "#             time = times[hearing]\n",
    "#         # Append\n",
    "#         dates.append(date)\n",
    "#         times.append(time)\n",
    "\n",
    "#     # Use concurrent requests to process hearings\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         futures = [executor.submit(process_hearing, link) for link in link_extension]\n",
    "#         concurrent.futures.wait(futures)\n",
    "\n",
    "#     # Zipping into single dataframe\n",
    "#     day_results = pd.DataFrame(zip(dates, committee_titles, hearing_titles, times, link_extension), columns=[\"Date\", \"Committee\", \"Hearing Title\", \"Time\", \"Link\"])\n",
    "\n",
    "#     return day_results\n",
    "\n",
    "# # Example usage\n",
    "# datestart = \"01/01/2023\"\n",
    "# dateend = \"06/30/2023\"\n",
    "# results = gethearingrange(datestart, dateend)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART ONE: GATHER COMMITTEE ASSIGNMENTS \n",
    "This part takes forever if you're doing prior congresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getassignments(congress,rerun=False):\n",
    "\n",
    "# check if assignments.csv exists already, if it doesn't then continue\n",
    "\n",
    "    if rerun == False and os.path.exists(directory+\"/assignments.csv\"):\n",
    "        member_data = pd.read_csv(directory+\"/assignments.csv\", index_col=0)\n",
    "        return(member_data)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #uses web archive to get committee assignments for each congress (archive not needed for current congress)\n",
    "        import time\n",
    "        import concurrent.futures\n",
    "        from requests_futures.sessions import FuturesSession\n",
    "\n",
    "        # Create a session\n",
    "        session = FuturesSession()\n",
    "\n",
    "        # Link for specific congress (including relevant date for webarchive)\n",
    "        Com_Dict = {118:\"\", #XXX update once past this congress\n",
    "                    117:\"https://web.archive.org/web/20221009111811/\",\n",
    "                    116:\"https://web.archive.org/web/20201026031027/\",\n",
    "                    115:\"https://web.archive.org/web/20181026031027/\"}\n",
    "\n",
    "\n",
    "        ComLink_Dict = {118:\"http://clerk.house.gov\",#XXX update once past this congress\n",
    "                        117:\"http://web.archive.org\",\n",
    "                        116:\"http://web.archive.org\",\n",
    "                        115:\"http://web.archive.org\"}\n",
    "\n",
    "\n",
    "        clerk = Com_Dict.get(congress)+\"http://clerk.house.gov/committees\"\n",
    "\n",
    "        webpage = requests.get(clerk)\n",
    "        tree = html.fromstring(webpage.content)\n",
    "\n",
    "        com_titles = tree.xpath(\"//div[@class='col-sm-11 col-xs-10 library-committeePanel-heading']//a//text()\")\n",
    "        com_links = tree.xpath(\"//div[@class='col-sm-11 col-xs-10 library-committeePanel-heading']//a//@href\")\n",
    "\n",
    "        com_links = [ComLink_Dict.get(congress)+end for end in com_links]\n",
    "\n",
    "        if congress == 116 or congress == 117:\n",
    "            com_links = com_links + [\"http://clerk.house.gov/committees/VC00\"]\n",
    "            \n",
    "        com_codes = [title[len(title)-4:len(title)] for title in com_links]\n",
    "\n",
    "        member_data = {}\n",
    "\n",
    "        def get_and_parse(url):\n",
    "            response = session.get(url).result()\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Your parsing code here\n",
    "            members = tree.xpath(\"//ul[@id='majority-members' or @id='minority-members']//li/a/span/text()\")\n",
    "            members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "            members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "            members = [str(member).replace(\"?\",\"e\") for member in members]\n",
    "\n",
    "            # Extract the committee code from the URL\n",
    "            com_code = url[len(url)-4:len(url)]\n",
    "\n",
    "            # Add the members to the dictionary\n",
    "            if com_code not in member_data:\n",
    "                member_data[com_code] = set()\n",
    "            member_data[com_code].update(members)\n",
    "\n",
    "            # Subcommittees\n",
    "            subcom_links = tree.xpath(\"//section[@class='subcommittees']//ul[@class='library-list_ul']//li//a/@href\")\n",
    "            subcom_links = [sub.replace(\"https\",\"http\") for sub in subcom_links]\n",
    "            subcom_links = [ComLink_Dict.get(congress)+end for end in subcom_links]\n",
    "            subcom_links = [link.replace(\"///\",\"/\") for link in subcom_links]\n",
    "\n",
    "            subcom_codes = [title[len(title)-4:len(title)] for title in subcom_links]\n",
    "\n",
    "            # Iterate over subcommittees, get members\n",
    "            for subcom in range(len(subcom_links)):\n",
    "                single_subcom = session.get(subcom_links[subcom]).result()\n",
    "                tree = html.fromstring(single_subcom.content)\n",
    "                members = tree.xpath(\"//ul[@id='majority-members' or @id='minority-members']//li/a/span/text()\")\n",
    "                members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "                members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "                members = [str(member).replace(\"?\",\"e\") for member in members]\n",
    "\n",
    "                # Add the members to the dictionary\n",
    "                if subcom_codes[subcom] not in member_data:\n",
    "                    member_data[subcom_codes[subcom]] = set()\n",
    "\n",
    "                member_data[subcom_codes[subcom]].update(members)\n",
    "\n",
    "\n",
    "        for com in range(len(com_links)):\n",
    "            # Add a delay\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Use concurrent requests\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                executor.map(get_and_parse, com_links)\n",
    "\n",
    "        # Find the maximum length of arrays in member_data\n",
    "        max_length = max(len(arr) for arr in member_data.values())\n",
    "\n",
    "        # Pad arrays with empty strings to make them the same length\n",
    "        for key in member_data:\n",
    "            member_data[key] = list(member_data[key]) + [''] * (max_length - len(member_data[key]))\n",
    "\n",
    "        # Convert member_data dict to dataframe\n",
    "        member_data = pd.DataFrame(member_data).transpose()\n",
    "\n",
    "        member_data.to_csv(directory+\"/assignments.csv\")\n",
    "\n",
    "        return(member_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART TWO: GET COMMITTEE CODES FOR HEARINGS, GATHER HEARING DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethearingdata(congress,member_data,rerun): #rerun = no, yes, or fromdate\n",
    "\n",
    "    #check if hearings.csv exists already, if it doesn't then continue\n",
    "\n",
    "    if rerun == \"no\" and os.path.exists(directory+\"/hearings.csv\"):\n",
    "        hearing_data = pd.read_csv(directory+\"/hearings.csv\")\n",
    "        return(hearing_data)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        #if rerun is fromdate, get hearings from max date in hearings.csv to today\n",
    "        if rerun == \"fromdate\" and os.path.exists(directory+\"/hearings.csv\"):\n",
    "            ## runs from max date in hearings.csv (last hearing) to today XXX right now set to end of second quarter 2024\n",
    "            hearing_data = gethearingrange(hearing_data_original[\"Date\"].max(),date(2024, 7, 31)) #datetime.now().date() for today's date\n",
    "            \n",
    "\n",
    "        else:\n",
    "            dates_start = {118:\"01/03/2023\",\n",
    "                        117:\"01/03/2021\",\n",
    "                        116:\"01/03/2019\",\n",
    "                        115:\"01/03/2017\"}\n",
    "            \n",
    "            dates_end = {118:\"01/02/2025\",#XXX\n",
    "                        117:\"01/02/2023\",\n",
    "                        116:\"01/02/2021\",\n",
    "                        115:\"01/02/2019\"}\n",
    "            \n",
    "            hearing_data = gethearingrange(dates_start.get(congress),dates_end.get(congress))\n",
    "\n",
    "        #import replacement (comcode) files\n",
    "\n",
    "        replacement = pd.read_csv(\"replacement\"+str(congress)+\".csv\")\n",
    "\n",
    "        # #drop all comcodes without member assignments from clerk.gov\n",
    "        codes_to_drop = [value for value in replacement[\"Code\"].unique() if value not in member_data.index.unique()]\n",
    "        replacement = replacement[~replacement[\"Code\"].isin(codes_to_drop)]\n",
    "\n",
    "        #convert committees to lowercase for merging\n",
    "        hearing_data[\"committee-low\"] = hearing_data[\"Committee\"].str.lower()\n",
    "        replacement[\"committee-low\"] = replacement[\"Committee\"].str.lower()\n",
    "        \n",
    "        #drop original column in replacement df\n",
    "        replacement.drop([\"Committee\"],axis=1,inplace=True)\n",
    "        \n",
    "        #merge codes and names\n",
    "        hearing_data = pd.merge(hearing_data,replacement,on=\"committee-low\",how=\"left\")\n",
    "        \n",
    "        #drop lowercase column\n",
    "        hearing_data.drop([\"committee-low\"],axis=1,inplace=True)\n",
    "\n",
    "        #if rerun is true, concat hearing_data_original\n",
    "        if rerun == \"fromdate\" and os.path.exists(directory+\"/hearings.csv\"):\n",
    "            hearing_data_original = pd.read_csv(directory+\"/hearings.csv\")\n",
    "            hearing_data = pd.concat([hearing_data_original,hearing_data],ignore_index=True)\n",
    "\n",
    "        #drop duplicates\n",
    "        hearing_data.drop_duplicates(subset=[\"Link\"], inplace=True)\n",
    "\n",
    "        hearing_data.to_csv(directory+\"/hearings.csv\",index=False)\n",
    "        \n",
    "        return(hearing_data)\n",
    "\n",
    "def testmatches(hearing_data):\n",
    "    import pandas as pd\n",
    "    match = pd.DataFrame(hearing_data[hearing_data[\"Code\"].isna()][\"Committee\"].unique())\n",
    "    match.to_csv(directory+\"/match.csv\",index=False)\n",
    "    return(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getconflicts(member_data,hearing_data):\n",
    "\n",
    "    results = pd.DataFrame(columns=[\"MC\",\"Hearing 1 Code\",\"Hearing 1 Link\",\"Hearing 2 Code\",\"Hearing 2 Link\",\"Date\"])\n",
    "    unique_dates = hearing_data[\"Date\"].unique()\n",
    "\n",
    "    # convert to datetime\n",
    "    hearing_data[\"Time\"] = [datetime.strptime(time,\"%I:%M %p\") for time in hearing_data[\"Time\"]]\n",
    "\n",
    "    # add two hours to [\"Time\"] column in hearing_data\n",
    "    hearing_data[\"Time+2\"] = hearing_data[\"Time\"] + timedelta(hours=2)\n",
    "\n",
    "    for unique_day in unique_dates:\n",
    "\n",
    "        #get dataframe of all hearings in selected day\n",
    "        day = hearing_data[hearing_data[\"Date\"]==unique_day]\n",
    "\n",
    "        #make sure there are at least two different committees meeting today\n",
    "        if len(day[\"Code\"].unique()) >= 2:\n",
    "\n",
    "            #ADD TWO HOURS TO HEARINGS TO CREATE HEARING LENGTH\n",
    "\n",
    "            counts = day[\"Code\"].value_counts()\n",
    "\n",
    "            # day[\"Time\"] = [datetime.strptime(time,\"%H:%M %p\") for time in day[\"Time\"]]\n",
    "            # ### XXX Note to self - look into why i set it up this way before rather than just adding two hours across the board\n",
    "            # Time_2 = list()\n",
    "            # for index, row in day.iterrows():\n",
    "            #     if counts.loc[row[\"Code\"]] == 1:\n",
    "            #         Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "            #     elif row[\"Time\"]+timedelta(hours=2) < day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max():\n",
    "            #         Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "            #     elif row[\"Time\"] == day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max():\n",
    "            #         Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "            #     else:\n",
    "            #         Time_2.append(day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max())\n",
    "\n",
    "            # day[\"Time+2\"] = Time_2\n",
    "\n",
    "            #get overlapping hearings\n",
    "            combos = pd.DataFrame(itertools.combinations(day.index,2),columns = [\"Hearing Code 1\",\"Hearing Code 2\"])\n",
    "\n",
    "            overlap = list()\n",
    "            for combo in range(len(combos)):\n",
    "                hearing1 = combos[\"Hearing Code 1\"][combo]\n",
    "                hearing2 = combos[\"Hearing Code 2\"][combo]\n",
    "                latest_start = max(day[\"Time\"][hearing1],day[\"Time\"][hearing2])\n",
    "                earliest_end = min(day[\"Time+2\"][hearing1],day[\"Time+2\"][hearing2])\n",
    "                if (earliest_end - latest_start) > timedelta(hours=0):\n",
    "                    overlap.append(\"Overlaps\")\n",
    "                else:\n",
    "                    overlap.append(\"No Overlap\")\n",
    "            combos[\"Overlap\"] = overlap\n",
    "            combos = combos[combos[\"Overlap\"]==\"Overlaps\"]\n",
    "            combos.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            #for each combination of committees in one day, determine which committees conflict \n",
    "                #and then get the members that are in both\n",
    "\n",
    "            # change time if it's same committee overlapping\n",
    "            for combo in range(len(combos)):\n",
    "                hearing_1 = day[day.index==combos[\"Hearing Code 1\"][combo]]\n",
    "                hearing_2 = day[day.index==combos[\"Hearing Code 2\"][combo]]\n",
    "\n",
    "                hearing_1.reset_index(drop=True,inplace=True)\n",
    "                hearing_2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                hearing_1 = hearing_1[\"Code\"][0]\n",
    "                hearing_2 = hearing_2[\"Code\"][0]\n",
    "\n",
    "            for combo in range(len(combos)):\n",
    "                #get committee code for hearing\n",
    "                hearing_1 = day[day.index==combos[\"Hearing Code 1\"][combo]]\n",
    "                hearing_2 = day[day.index==combos[\"Hearing Code 2\"][combo]]\n",
    "\n",
    "                hearing_1.reset_index(drop=True,inplace=True)\n",
    "                hearing_2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                hearing_1 = hearing_1[\"Code\"][0]\n",
    "                hearing_2 = hearing_2[\"Code\"][0]\n",
    "\n",
    "                #get members in relevant hearings\n",
    "                try:\n",
    "                    hearing_1_members = member_data[member_data.index == hearing_1].dropna(axis=1).iloc[0,:]\n",
    "                    hearing_2_members = member_data[member_data.index == hearing_2].dropna(axis=1).iloc[0,:]\n",
    "\n",
    "\n",
    "                    #check to make sure it is not the same committee conflicting\n",
    "                    if hearing_1 != hearing_2:\n",
    "                        #get members that are in both conflicting committees\n",
    "                        overlapping_members = [value for value in hearing_1_members if str(value) in str(hearing_2_members)]\n",
    "                        overlapping_members = pd.DataFrame(overlapping_members)\n",
    "                        #if there are overlapping members, add to results\n",
    "                        if len(overlapping_members)>0:\n",
    "                            hearinglist = [[day.loc[combos[\"Hearing Code 1\"][combo]][\"Code\"]]*len(overlapping_members),\n",
    "                                        [day.loc[combos[\"Hearing Code 1\"][combo]][\"Link\"]]*len(overlapping_members),\n",
    "                                        [day.loc[combos[\"Hearing Code 2\"][combo]][\"Code\"]]*len(overlapping_members),\n",
    "                                        [day.loc[combos[\"Hearing Code 2\"][combo]][\"Link\"]]*len(overlapping_members),\n",
    "                                        [day.loc[combos[\"Hearing Code 2\"][combo]][\"Date\"]]*len(overlapping_members)]\n",
    "                            hearinglist = pd.DataFrame(hearinglist).transpose()\n",
    "                            res = pd.merge(overlapping_members,hearinglist,left_index=True,right_index=True)\n",
    "                            res.columns = [\"MC\",\"Hearing 1 Code\",\"Hearing 1 Link\",\"Hearing 2 Code\",\"Hearing 2 Link\",\"Date\"]\n",
    "                            results = pd.concat([results, res])\n",
    "                            #results = results.append(res)  \n",
    "\n",
    "                except:\n",
    "                    print(\"Issue with: \",hearing_1,\" or \",hearing_2)\n",
    "\n",
    "    results.reset_index(inplace=True,drop=True)\n",
    "    results.to_csv(directory+\"/results.csv\",index=False)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART FOUR: RUN EVERYTHING TO GET RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runeverything(congress):\n",
    "\n",
    "    member_data = getassignments(congress) ## to rerun, add rerun=True\n",
    "    print(\"member_data success\")\n",
    "    hearing_data = gethearingdata(congress,member_data,rerun=True) ## to rerun, add rerun=\"yes\" to rerun entire congress or rerun = \"fromdate\" to rerun from last date in hearings.csv\n",
    "    print(\"hearing_data success\")\n",
    "    match = testmatches(hearing_data)\n",
    "    print(\"match success\")\n",
    "    if len(match) > 0:\n",
    "        display([i for i in match[0]])\n",
    "        return(member_data,hearing_data)\n",
    "    else:\n",
    "        results = getconflicts(member_data,hearing_data)\n",
    "        return(results,member_data,hearing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Everything for Specific Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_data success\n",
      "hearing_data success\n",
      "match success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MC</th>\n",
       "      <th>Hearing 1 Code</th>\n",
       "      <th>Hearing 1 Link</th>\n",
       "      <th>Hearing 2 Code</th>\n",
       "      <th>Hearing 2 Link</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gregory F. Murphy</td>\n",
       "      <td>WM00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>VR00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Tuesday, January 31, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nancy Mace</td>\n",
       "      <td>GO00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>VR00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Tuesday, January 31, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gary J. Palmer</td>\n",
       "      <td>GO00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>IF00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Tuesday, January 31, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mariannette Miller-Meeks</td>\n",
       "      <td>VR00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>IF00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Tuesday, January 31, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erin Houchin</td>\n",
       "      <td>ED00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>RU00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Tuesday, January 31, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Cori Bush</td>\n",
       "      <td>JU00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>GO06</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Wednesday, July 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>Harriet M. Hageman</td>\n",
       "      <td>JU00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>II24</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Wednesday, July 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>Scott Fitzgerald</td>\n",
       "      <td>JU00</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>BA04</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Wednesday, July 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>Nydia M. Velezquez</td>\n",
       "      <td>II24</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>BA04</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Wednesday, July 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>Nicholas A. Langworthy</td>\n",
       "      <td>AG22</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>GO12</td>\n",
       "      <td>https://docs.house.gov/Committee/Calendar/ByEv...</td>\n",
       "      <td>Thursday, July 25, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9894 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MC Hearing 1 Code  \\\n",
       "0             Gregory F. Murphy           WM00   \n",
       "1                    Nancy Mace           GO00   \n",
       "2                Gary J. Palmer           GO00   \n",
       "3      Mariannette Miller-Meeks           VR00   \n",
       "4                  Erin Houchin           ED00   \n",
       "...                         ...            ...   \n",
       "9889                  Cori Bush           JU00   \n",
       "9890         Harriet M. Hageman           JU00   \n",
       "9891           Scott Fitzgerald           JU00   \n",
       "9892         Nydia M. Velezquez           II24   \n",
       "9893     Nicholas A. Langworthy           AG22   \n",
       "\n",
       "                                         Hearing 1 Link Hearing 2 Code  \\\n",
       "0     https://docs.house.gov/Committee/Calendar/ByEv...           VR00   \n",
       "1     https://docs.house.gov/Committee/Calendar/ByEv...           VR00   \n",
       "2     https://docs.house.gov/Committee/Calendar/ByEv...           IF00   \n",
       "3     https://docs.house.gov/Committee/Calendar/ByEv...           IF00   \n",
       "4     https://docs.house.gov/Committee/Calendar/ByEv...           RU00   \n",
       "...                                                 ...            ...   \n",
       "9889  https://docs.house.gov/Committee/Calendar/ByEv...           GO06   \n",
       "9890  https://docs.house.gov/Committee/Calendar/ByEv...           II24   \n",
       "9891  https://docs.house.gov/Committee/Calendar/ByEv...           BA04   \n",
       "9892  https://docs.house.gov/Committee/Calendar/ByEv...           BA04   \n",
       "9893  https://docs.house.gov/Committee/Calendar/ByEv...           GO12   \n",
       "\n",
       "                                         Hearing 2 Link  \\\n",
       "0     https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "1     https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "2     https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "3     https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "4     https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "...                                                 ...   \n",
       "9889  https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "9890  https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "9891  https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "9892  https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "9893  https://docs.house.gov/Committee/Calendar/ByEv...   \n",
       "\n",
       "                           Date  \n",
       "0     Tuesday, January 31, 2023  \n",
       "1     Tuesday, January 31, 2023  \n",
       "2     Tuesday, January 31, 2023  \n",
       "3     Tuesday, January 31, 2023  \n",
       "4     Tuesday, January 31, 2023  \n",
       "...                         ...  \n",
       "9889   Wednesday, July 24, 2024  \n",
       "9890   Wednesday, July 24, 2024  \n",
       "9891   Wednesday, July 24, 2024  \n",
       "9892   Wednesday, July 24, 2024  \n",
       "9893    Thursday, July 25, 2024  \n",
       "\n",
       "[9894 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results,member_data,hearing_data = runeverything(congress)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PART ONE: GATHER COMMITTEE ASSIGNMENTS (this part takes forever if you're doing prior congresses)\n",
    "\n",
    "# ##PRE 2020\n",
    "# def getassignments(congress):\n",
    "#     import requests \n",
    "#     import pandas as pd\n",
    "#     from lxml import html    \n",
    "#     from datetime import datetime, timedelta\n",
    "    \n",
    "#     Com_Dict = {117:\"\",\n",
    "#                116:\"https://web.archive.org/web/20191219040247/\"}\n",
    "\n",
    "\n",
    "\n",
    "#     member_data = pd.DataFrame()\n",
    "\n",
    "#     clerk = Com_Dict.get(congress)+\"http://clerk.house.gov/committee_info/index.aspx\"\n",
    "#     webpage = requests.get(clerk)\n",
    "#     tree = html.fromstring(webpage.content)\n",
    "\n",
    "#     com_titles = tree.xpath(\"//div[@id='com_directory']//ul//li//a//text()\")\n",
    "#     com_links = tree.xpath(\"//div[@id='com_directory']//ul//li//a//@href\")\n",
    "\n",
    "#     ComLink_Dict = {117:\"http://clerk.house.gov\",\n",
    "#                116:\"https://web.archive.org/\"}\n",
    "\n",
    "#     com_links = [ComLink_Dict.get(congress)+end for end in com_links]\n",
    "#     com_codes = [title[title.find(\"=\")+1:len(title)] for title in com_links]\n",
    "\n",
    "#     for com in range(len(com_links)):\n",
    "#         singlecom = requests.get(com_links[com])\n",
    "#         tree = html.fromstring(singlecom.content)\n",
    "\n",
    "#         members = tree.xpath(\"//div[@id='primary_group' or @id='secondary_group']//ol//li/a/text()\")\n",
    "#         members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "#         members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "\n",
    "#         member_data = member_data.append(pd.DataFrame(members,columns=[com_codes[com]]).transpose())\n",
    "\n",
    "#         subcom_links = tree.xpath(\"//div[@id='subcom_list']//ul//li//@href\")\n",
    "#         subcom_links = [ComLink_Dict.get(congress)+end for end in subcom_links]\n",
    "#         subcom_links = [link.replace(\"///\",\"/\") for link in subcom_links]\n",
    "\n",
    "#         subcom_codes = [title[title.find(\"=\")+1:len(title)] for title in subcom_links]\n",
    "\n",
    "#         for subcom in range(len(subcom_links)):\n",
    "#             single_subcom = requests.get(subcom_links[subcom])\n",
    "#             tree = html.fromstring(single_subcom.content)\n",
    "#             members = tree.xpath(\"//div[@id='primary_group' or @id='secondary_group']//ol//li/a/text()\")\n",
    "#             members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "#             members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "#             member_data = member_data.append(pd.DataFrame(members,columns=[subcom_codes[subcom]]).transpose())\n",
    "            \n",
    "#     return(member_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
