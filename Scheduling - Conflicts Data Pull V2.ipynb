{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this pulls hearings for one day\n",
    "def hearingpull(date):\n",
    "    import requests \n",
    "    import pandas as pd\n",
    "    from lxml import html    \n",
    "    from datetime import datetime,timedelta\n",
    "\n",
    "    #formatting url\n",
    "    day_url = \"https://docs.house.gov/Committee/Calendar/ByDay.aspx?DayID=\" + date.strftime(\"%m%d%Y\")\n",
    "\n",
    "    #import webpage and create tree\n",
    "    webpage = requests.get(day_url)\n",
    "    tree = html.fromstring(webpage.content)\n",
    "\n",
    "    #importing and formatting hearing titles\n",
    "    hearing_titles = tree.xpath(\"//table//a[@title]//text()[normalize-space()]\")\n",
    "    hearing_titles = [sub.replace('\\r\\n', '') for sub in hearing_titles] \n",
    "    hearing_titles = [sub.strip() for sub in hearing_titles]\n",
    "    hearing_titles = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace(\"???\",\" \") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace(\"'\",\"\") for sub in hearing_titles]\n",
    "    hearing_titles = [str(sub).replace('\"',\"\") for sub in hearing_titles]\n",
    "\n",
    "    #import and format committee titles\n",
    "    committee_titles = tree.xpath(\"//table//span[@title]//text()[normalize-space()]\")\n",
    "    committee_titles = [sub.replace('\\r\\n', '') for sub in committee_titles] \n",
    "    committee_titles = [sub.strip() for sub in committee_titles]\n",
    "    committee_titles = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace(\"???\",\" \") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace(\"'\",\"\") for sub in committee_titles]\n",
    "    committee_titles = [str(sub).replace('\"',\"\") for sub in committee_titles]\n",
    "\n",
    "\n",
    "    #import and format links\n",
    "    link_extension = tree.xpath(\"//table//a//@href\")\n",
    "    link_extension = [\"https://docs.house.gov/Committee/Calendar/\"+ex for ex in link_extension]\n",
    "\n",
    "    #import times and dates\n",
    "    times = list()\n",
    "    dates = list()\n",
    "\n",
    "    for hearing in range(len(link_extension)):\n",
    "        hearing_link = requests.get(link_extension[hearing])\n",
    "        hearing_tree = html.fromstring(hearing_link.content)\n",
    "        try:\n",
    "            datestring = hearing_tree.xpath(\"//div[@class='meeting-date']//p/text()[normalize-space()]\")\n",
    "            #get dates\n",
    "            date = datestring[0][0:datestring[0].find(\"(\")-1]\n",
    "            date = date.replace('\\r\\n', '')\n",
    "            date = date.strip()\n",
    "            #get times\n",
    "            time = datestring[0][datestring[0].find(\"(\"):len(datestring[0])]\n",
    "            time = time.replace('\\r\\n', '')\n",
    "            time = time.replace('(', '')\n",
    "            time = time.replace(')', '')\n",
    "            if time.find(\"-\") > 0:\n",
    "                time = time[0:time.find(\"-\")]\n",
    "            time = time.strip()\n",
    "        except:\n",
    "            date = tree.xpath(\"//div[@id='body']//span[@id='LabelPageTitle']//text()[normalize-space()]\")[0]\n",
    "            times = tree.xpath(\"//div//table[@class='table table-bordered']//tr//td[2]//span[@class='text-small']//text()[normalize-space()]\")\n",
    "            times = [sub.replace('\\r\\n', '') for sub in times] \n",
    "            times = [sub.strip() for sub in times]\n",
    "            times = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in times]\n",
    "            times = [str(sub).replace(\"???\",\" \") for sub in times]\n",
    "            times = [str(sub).replace(\"'\",\"\") for sub in times]\n",
    "            times = [str(sub).replace('\"',\"\") for sub in times]\n",
    "            time = times[hearing]\n",
    "        #append\n",
    "        dates.append(date)\n",
    "        times.append(time)\n",
    "\n",
    "    #zipping into single dataframe\n",
    "    day_results = pd.DataFrame(zip(dates,committee_titles,hearing_titles,times,link_extension),columns=[\"Date\",\"Committee\",\"Hearing Title\",\"Time\",\"Link\"])\n",
    "\n",
    "    return(day_results)\n",
    "\n",
    "#this pulls hearings for a date range\n",
    "def gethearingrange(datestart,dateend):\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    results = pd.DataFrame(columns=[\"Date\",\"Committee\",\"Hearing Title\",\"Time\",\"Link\"])\n",
    "\n",
    "    datestart = datetime.strptime(datestart,\"%m/%d/%Y\").date()\n",
    "    dateend = datetime.strptime(dateend,\"%m/%d/%Y\").date()\n",
    "    \n",
    "    while datestart <= dateend:\n",
    "        results = results.append(hearingpull(datestart))\n",
    "        datestart += timedelta(days=1)\n",
    "    \n",
    "    #remove misc. spaces from committee column\n",
    "    results[\"Committee\"] = [re.sub(' +', ' ',com) for com in results[\"Committee\"]]\n",
    "    \n",
    "    results[\"Time\"] = [time.replace(\"local time\",\"\") for time in results[\"Time\"]]\n",
    "    results[\"Time\"] = [time.strip() for time in results[\"Time\"]]\n",
    "    \n",
    "    results = results.drop_duplicates(subset=[\"Link\"])\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART ONE: GATHER COMMITTEE ASSIGNMENTS (this part takes forever if you're doing pre-116)\n",
    "\n",
    "def getassignments(congress):\n",
    "    import requests \n",
    "    import pandas as pd\n",
    "    from lxml import html    \n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    Com_Dict = {116:\"\",\n",
    "               115:\"https://web.archive.org/web/20181226060001/\",\n",
    "               114:\"https://web.archive.org/web/20161203054650/\",\n",
    "               113:\"https://web.archive.org/web/20141205200618/\"}\n",
    "\n",
    "\n",
    "\n",
    "    member_data = pd.DataFrame()\n",
    "\n",
    "    clerk = Com_Dict.get(congress)+\"http://clerk.house.gov/committee_info/index.aspx\"\n",
    "    webpage = requests.get(clerk)\n",
    "    tree = html.fromstring(webpage.content)\n",
    "\n",
    "    com_titles = tree.xpath(\"//div[@id='com_directory']//ul//li//a//text()\")\n",
    "    com_links = tree.xpath(\"//div[@id='com_directory']//ul//li//a//@href\")\n",
    "\n",
    "    ComLink_Dict = {116:\"http://clerk.house.gov\",\n",
    "               115:\"https://web.archive.org/\",\n",
    "               114:\"https://web.archive.org/\",\n",
    "               113:\"https://web.archive.org/\"}\n",
    "\n",
    "    com_links = [ComLink_Dict.get(congress)+end for end in com_links]\n",
    "    com_codes = [title[title.find(\"=\")+1:len(title)] for title in com_links]\n",
    "\n",
    "    for com in range(len(com_links)):\n",
    "        singlecom = requests.get(com_links[com])\n",
    "        tree = html.fromstring(singlecom.content)\n",
    "\n",
    "        members = tree.xpath(\"//div[@id='primary_group' or @id='secondary_group']//ol//li/a/text()\")\n",
    "        members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "        members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "\n",
    "        member_data = member_data.append(pd.DataFrame(members,columns=[com_codes[com]]).transpose())\n",
    "\n",
    "        subcom_links = tree.xpath(\"//div[@id='subcom_list']//ul//li//@href\")\n",
    "        subcom_links = [ComLink_Dict.get(congress)+end for end in subcom_links]\n",
    "        subcom_links = [link.replace(\"///\",\"/\") for link in subcom_links]\n",
    "\n",
    "        subcom_codes = [title[title.find(\"=\")+1:len(title)] for title in subcom_links]\n",
    "\n",
    "        for subcom in range(len(subcom_links)):\n",
    "            single_subcom = requests.get(subcom_links[subcom])\n",
    "            tree = html.fromstring(single_subcom.content)\n",
    "            members = tree.xpath(\"//div[@id='primary_group' or @id='secondary_group']//ol//li/a/text()\")\n",
    "            members = [sub.encode(\"ascii\", \"replace\").decode(\"utf-8\") for sub in members]\n",
    "            members = [str(member).replace(\"??\",\"e\") for member in members]\n",
    "            member_data = member_data.append(pd.DataFrame(members,columns=[subcom_codes[subcom]]).transpose())\n",
    "            \n",
    "    return(member_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART TWO: GET COMMITTEE CODES FOR HEARINGS, GATHER HEARING DATA\n",
    "def gethearingdata(congress,member_data):\n",
    "    import pandas as pd\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    dates_start = {116:\"01/01/2019\",\n",
    "                   115:\"01/01/2017\",\n",
    "                   114:\"01/01/2015\",\n",
    "                   113:\"01/01/2013\"}\n",
    "    dates_end = {116:\"12/31/2019\",\n",
    "                   115:\"12/31/2018\",\n",
    "                   114:\"12/31/2016\",\n",
    "                   113:\"12/31/2014\"}\n",
    "    hearing_data = gethearingrange(dates_start.get(congress),dates_end.get(congress))\n",
    "\n",
    "    #import replacement (comcode) files\n",
    "\n",
    "    replacement = pd.read_csv(str(\"https://raw.githubusercontent.com/rachelorey/Scheduling-Conflicts-in-Congress/master/replacement\"+str(congress)+\".csv\"))\n",
    "\n",
    "    # #drop all comcodes without member assignments from clerk.gov\n",
    "    codes_to_drop = [value for value in replacement[\"Code\"].unique() if value not in member_data.index.unique()]\n",
    "    replacement = replacement[~replacement[\"Code\"].isin(codes_to_drop)]\n",
    "\n",
    "    #convert committees to lowercase for merging\n",
    "    hearing_data[\"committee-low\"] = hearing_data[\"Committee\"].str.lower()\n",
    "    replacement[\"committee-low\"] = replacement[\"Committee\"].str.lower()\n",
    "    \n",
    "    #drop original column in replacement df\n",
    "    replacement.drop([\"Committee\"],axis=1,inplace=True)\n",
    "    \n",
    "    #merge codes and names\n",
    "    hearing_data = pd.merge(hearing_data,replacement,on=\"committee-low\",how=\"left\")\n",
    "    \n",
    "    #drop lowercase column\n",
    "    hearing_data.drop([\"committee-low\"],axis=1,inplace=True)\n",
    "    \n",
    "    return(hearing_data)\n",
    "\n",
    "def testmatches(hearing_data):\n",
    "    import pandas as pd\n",
    "    match = pd.DataFrame(hearing_data[hearing_data[\"Code\"].isna()][\"Committee\"].unique())\n",
    "    return(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART THREE: LOOK FOR SCHEDULING CONFLICTS\n",
    "\n",
    "def getconflicts(member_data,hearing_data):\n",
    "    import pandas as pd\n",
    "    from datetime import datetime,timedelta\n",
    "    import itertools\n",
    "\n",
    "    results = pd.DataFrame(columns=[\"MC\",\"Hearing 1 Code\",\"Hearing 1 Link\",\"Hearing 2 Code\",\"Hearing 2 Link\",\"Date\"])\n",
    "    unique_dates = hearing_data[\"Date\"].unique()\n",
    "\n",
    "    for unique_day in unique_dates:\n",
    "\n",
    "        #get dataframe of all hearings in selected day\n",
    "        day = hearing_data[hearing_data[\"Date\"]==unique_day]\n",
    "\n",
    "        #make sure there are at least two different committees meeting today\n",
    "        if len(day[\"Code\"].unique()) >= 2:\n",
    "\n",
    "            #ADD TWO HOURS TO HEARINGS TO CREATE HEARING LENGTH\n",
    "\n",
    "            day[\"Time\"] = [datetime.strptime(time,\"%H:%M %p\") for time in day[\"Time\"]]\n",
    "            counts = day[\"Code\"].value_counts()\n",
    "\n",
    "            Time_2 = list()\n",
    "\n",
    "            for index, row in day.iterrows():\n",
    "                if counts.loc[row[\"Code\"]] == 1:\n",
    "                    Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "                elif row[\"Time\"]+timedelta(hours=2) < day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max():\n",
    "                    Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "                elif row[\"Time\"] == day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max():\n",
    "                    Time_2.append(row[\"Time\"]+timedelta(hours=2))\n",
    "                else:\n",
    "                    Time_2.append(day[day[\"Code\"]==row[\"Code\"]][\"Time\"].max())\n",
    "\n",
    "            day[\"Time+2\"] = Time_2\n",
    "\n",
    "            #get overlapping hearings\n",
    "            combos = pd.DataFrame(itertools.combinations(day.index,2),columns = [\"Hearing Code 1\",\"Hearing Code 2\"])\n",
    "\n",
    "            overlap = list()\n",
    "            for combo in range(len(combos)):\n",
    "                hearing1 = combos[\"Hearing Code 1\"][combo]\n",
    "                hearing2 = combos[\"Hearing Code 2\"][combo]\n",
    "                latest_start = max(day[\"Time\"][hearing1],day[\"Time\"][hearing2])\n",
    "                earliest_end = min(day[\"Time+2\"][hearing1],day[\"Time+2\"][hearing2])\n",
    "                if (earliest_end - latest_start) > timedelta(hours=0):\n",
    "                    overlap.append(\"Overlaps\")\n",
    "                else:\n",
    "                    overlap.append(\"No Overlap\")\n",
    "            combos[\"Overlap\"] = overlap\n",
    "            combos = combos[combos[\"Overlap\"]==\"Overlaps\"]\n",
    "            combos.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            #for each combination of committees in one day, determine which committees conflict \n",
    "                #and then get the members that are in both\n",
    "\n",
    "            # change time if it's same committee overlapping\n",
    "            for combo in range(len(combos)):\n",
    "                hearing_1 = day[day.index==combos[\"Hearing Code 1\"][combo]]\n",
    "                hearing_2 = day[day.index==combos[\"Hearing Code 2\"][combo]]\n",
    "\n",
    "                hearing_1.reset_index(drop=True,inplace=True)\n",
    "                hearing_2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                hearing_1 = hearing_1[\"Code\"][0]\n",
    "                hearing_2 = hearing_2[\"Code\"][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for combo in range(len(combos)):\n",
    "                #get committee code for hearing\n",
    "                hearing_1 = day[day.index==combos[\"Hearing Code 1\"][combo]]\n",
    "                hearing_2 = day[day.index==combos[\"Hearing Code 2\"][combo]]\n",
    "\n",
    "                hearing_1.reset_index(drop=True,inplace=True)\n",
    "                hearing_2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                hearing_1 = hearing_1[\"Code\"][0]\n",
    "                hearing_2 = hearing_2[\"Code\"][0]\n",
    "\n",
    "                #get members in relevant hearings\n",
    "                try:\n",
    "                    hearing_1_members = member_data[member_data.index == hearing_1].dropna(axis=1).iloc[0,:]\n",
    "                    hearing_2_members = member_data[member_data.index == hearing_2].dropna(axis=1).iloc[0,:]\n",
    "\n",
    "\n",
    "                    #check to make sure it is not the same committee conflicting\n",
    "                    if hearing_1 != hearing_2:\n",
    "                        #get members that are in both conflicting committees\n",
    "                        overlapping_members = [value for value in hearing_1_members if str(value) in str(hearing_2_members)]\n",
    "                        overlapping_members = pd.DataFrame(overlapping_members)\n",
    "                        #if there are overlapping members, add to results\n",
    "                        if len(overlapping_members)>0:\n",
    "                            hearinglist = [[day.loc[combos[\"Hearing Code 1\"][combo]][\"Code\"]]*len(overlapping_members),\n",
    "                                       [day.loc[combos[\"Hearing Code 1\"][combo]][\"Link\"]]*len(overlapping_members),\n",
    "                                       [day.loc[combos[\"Hearing Code 2\"][combo]][\"Code\"]]*len(overlapping_members),\n",
    "                                       [day.loc[combos[\"Hearing Code 2\"][combo]][\"Link\"]]*len(overlapping_members),\n",
    "                                      [day.loc[combos[\"Hearing Code 2\"][combo]][\"Date\"]]*len(overlapping_members)]\n",
    "                            hearinglist = pd.DataFrame(hearinglist).transpose()\n",
    "                            res = pd.merge(overlapping_members,hearinglist,left_index=True,right_index=True)\n",
    "                            res.columns = [\"MC\",\"Hearing 1 Code\",\"Hearing 1 Link\",\"Hearing 2 Code\",\"Hearing 2 Link\",\"Date\"]\n",
    "                            results = results.append(res)  \n",
    "                except:\n",
    "                    print(\"Issue with: \",hearing_1,\" or \",hearing_2)\n",
    "\n",
    "    results.reset_index(inplace=True,drop=True)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART FOUR: RUN EVERYTHING TO GET RESULTS\n",
    "def runeverything(congress):    \n",
    "    member_data = getassignments(congress)\n",
    "    hearing_data = gethearingdata(congress,member_data)\n",
    "    match = testmatches(hearing_data)\n",
    "    if len(match) > 0:\n",
    "        print(match)\n",
    "    results = getconflicts(member_data,hearing_data)\n",
    "    return(results,member_data,hearing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "congresses = [113,114,115,116]\n",
    "\n",
    "for congress in congresses:\n",
    "    \n",
    "    results,member_data,hearing_data = runeverything(congress)\n",
    "    results.to_csv(str(\"D:\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Modernization\\\\Scheduling Conflicts\\\\NEW\\\\Results\\\\results\"+str(congress)+\".csv\"),index=False)\n",
    "    hearing_data.to_csv(str(\"D:\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Modernization\\\\Scheduling Conflicts\\\\NEW\\\\Results\\\\hearings\"+str(congress)+\".csv\"),index=False)\n",
    "    member_data.to_csv(str(\"D:\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Modernization\\\\Scheduling Conflicts\\\\NEW\\\\Results\\\\assignments\"+str(congress)+\".csv\"))\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    member_count = pd.melt(member_data).drop([\"variable\"],axis=1)\n",
    "    member_count = member_count[~member_count[\"value\"].isna()]\n",
    "    member_count = pd.DataFrame(pd.value_counts(member_count[\"value\"]))\n",
    "    member_count.columns = [\"No. Committees\"]\n",
    "\n",
    "    conflict_count = pd.DataFrame(pd.value_counts(results[\"MC\"]))\n",
    "    conflict_by_assignments = pd.merge(member_count,conflict_count,left_index = True,right_index=True)\n",
    "    conflict_by_assignments.columns = [\"No. Committees\",\"No. Conflicts\"]\n",
    "\n",
    "    conflict_by_assignments.to_csv(\"D:\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Modernization\\\\Scheduling Conflicts\\\\NEW\\\\Results\\\\conflict_by_assignment\"+str(congress)+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
